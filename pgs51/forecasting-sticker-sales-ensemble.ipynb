{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder, label_binarize, OrdinalEncoder\n",
    "from category_encoders import CatBoostEncoder, MEstimateEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression, LinearRegression, Ridge, BayesianRidge\n",
    "\n",
    "from sklearn import set_config\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, mean_squared_error, precision_recall_curve, make_scorer, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, matthews_corrcoef, mean_absolute_percentage_error\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "from colorama import Fore, Style, init\n",
    "from copy import deepcopy\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, StratifiedKFold, KFold, RepeatedKFold, cross_val_score, StratifiedGroupKFold, GroupKFold\n",
    "from xgboost import DMatrix, XGBClassifier, XGBRegressor\n",
    "from lightgbm import log_evaluation, early_stopping, LGBMClassifier, LGBMRegressor, Dataset\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "from tqdm.notebook import tqdm\n",
    "from optuna.samplers import TPESampler, CmaEsSampler\n",
    "from optuna.pruners import HyperbandPruner\n",
    "from functools import partial\n",
    "from IPython.display import display_html, clear_output\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import gc\n",
    "import re\n",
    "import holidays\n",
    "import requests\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Configuration</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T02:31:03.118801Z",
     "iopub.status.busy": "2025-01-19T02:31:03.118040Z",
     "iopub.status.idle": "2025-01-19T02:31:03.639862Z",
     "shell.execute_reply": "2025-01-19T02:31:03.638794Z",
     "shell.execute_reply.started": "2025-01-19T02:31:03.118775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \n",
    "    state = 4152\n",
    "    n_splits = 5\n",
    "    early_stop = 200\n",
    "        \n",
    "    target = 'num_sold'\n",
    "    train = pd.read_csv('./datadown/train.csv', index_col='id')\n",
    "    test = pd.read_csv('./datadown/test.csv', index_col='id')\n",
    "    submission = pd.read_csv('./datadown/sample_submission.csv')\n",
    "\n",
    "    original_data = 'N'\n",
    "    outliers = 'N'\n",
    "    log_trf = 'Y'\n",
    "    scaler_trf = 'N'\n",
    "    feature_eng = 'Y'\n",
    "    missing = 'Y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T02:31:03.642165Z",
     "iopub.status.busy": "2025-01-19T02:31:03.641755Z",
     "iopub.status.idle": "2025-01-19T02:31:03.655250Z",
     "shell.execute_reply": "2025-01-19T02:31:03.654288Z",
     "shell.execute_reply.started": "2025-01-19T02:31:03.642131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EDA(Config):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cat_features = self.train.drop(self.target, axis=1).select_dtypes(include=['object']).columns.tolist()\n",
    "        self.num_features = self.train.drop(self.target, axis=1).select_dtypes(exclude=['object']).columns.tolist()\n",
    "        self.data_info()\n",
    "        self.cat_feature_plots()\n",
    "        self.target_plot()\n",
    "                \n",
    "    def data_info(self):\n",
    "        \n",
    "        for data, label in zip([self.train, self.test], ['Train', 'Test']):\n",
    "            table_style = [{'selector': 'th:not(.index_name)',\n",
    "                            'props': [('background-color', '#3cb371'),\n",
    "                                      ('color', '#FFFFFF'),\n",
    "                                      ('font-weight', 'bold'),\n",
    "                                      ('border', '1px solid #DCDCDC'),\n",
    "                                      ('text-align', 'center')]\n",
    "                            }, \n",
    "                            {'selector': 'tbody td',\n",
    "                             'props': [('border', '1px solid #DCDCDC'),\n",
    "                                       ('font-weight', 'normal')]\n",
    "                            }]\n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} head\\n')\n",
    "            display(data.head().style.set_table_styles(table_style))\n",
    "                           \n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} info\\n'+Style.RESET_ALL)               \n",
    "            display(data.info())\n",
    "            \n",
    "            print(Style.BRIGHT+Fore.GREEN+f'\\n{label} missing values\\n'+Style.RESET_ALL)               \n",
    "            display(data.isna().sum())\n",
    "        return self\n",
    "        \n",
    "    def cat_feature_plots(self):\n",
    "        fig, axes = plt.subplots(len(self.cat_features), 2 ,figsize = (18, len(self.cat_features) * 6), \n",
    "                                 gridspec_kw = {'hspace': 0.5, \n",
    "                                                'wspace': 0.2,\n",
    "                                               }\n",
    "                                )\n",
    "\n",
    "        for i, col in enumerate(self.cat_features):\n",
    "            \n",
    "            ax = axes[i,0]\n",
    "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='#3cb371')\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.set_title(f\"\\n{col} Train\")\n",
    "            \n",
    "            ax = axes[i,1]\n",
    "            sns.barplot(data=self.train[col].value_counts().nlargest(10).reset_index(), x=col, y='count', ax=ax, color='r')\n",
    "            ax.set(xlabel = '', ylabel = '')\n",
    "            ax.set_title(f\"\\n{col} Test\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def target_plot(self):\n",
    "        print(Style.BRIGHT+Fore.GREEN+f\"\\nTarget feature distribution\\n\")\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2 ,figsize = (14, 6), \n",
    "                                 gridspec_kw = {'hspace': 0.3, \n",
    "                                                'wspace': 0.2, \n",
    "                                                'width_ratios': [0.70, 0.30]\n",
    "                                               }\n",
    "                                )\n",
    "        ax = axes[0]\n",
    "        sns.kdeplot(data = self.train[self.target], \n",
    "                    color = '#3cb371', ax = ax, linewidth = 2\n",
    "                   )\n",
    "        ax.set(xlabel = '', ylabel = '')\n",
    "        ax.set_title(f\"\\n{self.target}\")\n",
    "        ax.grid()\n",
    "\n",
    "        ax = axes[1]\n",
    "        sns.boxplot(data = self.train, y = self.target, width = 0.5,\n",
    "                    linewidth = 1, fliersize= 1,\n",
    "                    ax = ax, color = '#3cb371'\n",
    "                   )\n",
    "        ax.set_title(f\"\\n{self.target}\")\n",
    "        ax.set(xlabel = '', ylabel = '')\n",
    "        ax.tick_params(axis='both', which='major')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-19T02:31:03.657095Z",
     "iopub.status.busy": "2025-01-19T02:31:03.656383Z",
     "iopub.status.idle": "2025-01-19T02:31:06.949932Z",
     "shell.execute_reply": "2025-01-19T02:31:06.948874Z",
     "shell.execute_reply.started": "2025-01-19T02:31:03.657062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# eda = EDA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:08:35.994911Z",
     "iopub.status.busy": "2025-01-17T10:08:35.994634Z",
     "iopub.status.idle": "2025-01-17T10:08:36.045533Z",
     "shell.execute_reply": "2025-01-17T10:08:36.044383Z",
     "shell.execute_reply.started": "2025-01-17T10:08:35.994888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Transform(Config):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        if Config.original_data == \"Y\":\n",
    "            self.train = pd.concat(\n",
    "                [self.train, self.train_org], ignore_index=True\n",
    "            ).drop_duplicates()\n",
    "            self.train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        self.num_features = (\n",
    "            self.train.drop(self.target, axis=1)\n",
    "            .select_dtypes(exclude=[\"object\", \"bool\"])\n",
    "            .columns.tolist()\n",
    "        )\n",
    "        self.cat_features = (\n",
    "            self.train.drop(self.target, axis=1)\n",
    "            .select_dtypes(include=[\"object\", \"bool\"])\n",
    "            .columns.tolist()\n",
    "        )\n",
    "\n",
    "        self.train_raw = self.train.copy()\n",
    "\n",
    "        if self.feature_eng == \"Y\":\n",
    "            self.train = self.new_features(self.train)\n",
    "            self.test = self.new_features(self.test)\n",
    "            self.train_raw = self.new_features(self.train_raw)\n",
    "\n",
    "        if self.missing == \"Y\":\n",
    "            self.missing_values()\n",
    "\n",
    "        self.num_features = (\n",
    "            self.train.drop(self.target, axis=1)\n",
    "            .select_dtypes(exclude=[\"object\", \"bool\"])\n",
    "            .columns.tolist()\n",
    "        )\n",
    "        self.cat_features = (\n",
    "            self.train.drop(self.target, axis=1)\n",
    "            .select_dtypes(include=[\"object\", \"bool\"])\n",
    "            .columns.tolist()\n",
    "        )\n",
    "\n",
    "        if self.outliers == \"Y\":\n",
    "            self.remove_outliers()\n",
    "\n",
    "        if self.log_trf == \"Y\":\n",
    "            self.log_transformation()\n",
    "\n",
    "        if self.scaler_trf == \"Y\":\n",
    "            self.scaler()\n",
    "\n",
    "        self.train_enc = self.train.copy()\n",
    "        self.test_enc = self.test.copy()\n",
    "        self.encode()\n",
    "\n",
    "        if self.outliers == \"Y\" or self.log_trf == \"Y\" or self.scaler_trf == \"Y\":\n",
    "            self.distribution()\n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        self.train[self.cat_features] = self.train[self.cat_features].astype(\"category\")\n",
    "        self.test[self.cat_features] = self.test[self.cat_features].astype(\"category\")\n",
    "\n",
    "        self.cat_features_card = []\n",
    "        for f in self.cat_features:\n",
    "            self.cat_features_card.append(self.train[f].nunique())\n",
    "\n",
    "        self.train = self.reduce_mem(self.train)\n",
    "        self.test = self.reduce_mem(self.test)\n",
    "\n",
    "        self.y = self.train[self.target]\n",
    "        self.train = self.train.drop(self.target, axis=1)\n",
    "        self.train_enc = self.train_enc.drop(self.target, axis=1)\n",
    "\n",
    "        return (\n",
    "            self.train,\n",
    "            self.train_enc,\n",
    "            self.y,\n",
    "            self.test,\n",
    "            self.test_enc,\n",
    "            self.cat_features,\n",
    "        )\n",
    "\n",
    "    def encode(self):\n",
    "        data = pd.concat([self.test, self.train])\n",
    "        oe = OrdinalEncoder()\n",
    "        data[self.cat_features] = oe.fit_transform(data[self.cat_features]).astype(\n",
    "            \"int\"\n",
    "        )\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        data[self.num_features + [self.target]] = scaler.fit_transform(\n",
    "            data[self.num_features + [self.target]]\n",
    "        )\n",
    "\n",
    "        self.train_enc = data[~data[self.target].isna()]\n",
    "        self.test_enc = data[data[self.target].isna()].drop(self.target, axis=1)\n",
    "\n",
    "    def new_features(self, data):\n",
    "        data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "        data[\"quarter\"] = data[\"date\"].dt.quarter.astype(\"object\")\n",
    "        data[\"month\"] = data[\"date\"].dt.month\n",
    "        data[\"month_sin\"] = np.sin(data[\"month\"] * (2 * np.pi / 12))\n",
    "        data[\"month_cos\"] = np.cos(data[\"month\"] * (2 * np.pi / 12))\n",
    "        data[\"day\"] = data[\"date\"].dt.day\n",
    "        data[\"day_sin\"] = np.sin(data[\"day\"] * (2 * np.pi / 31))\n",
    "        data[\"day_cos\"] = np.cos(data[\"day\"] * (2 * np.pi / 31))\n",
    "        data[\"day_of_week\"] = data[\"date\"].dt.dayofweek.astype(\"object\")\n",
    "        data[\"day_of_year\"] = data[\"date\"].dt.dayofyear.astype(\"object\")\n",
    "        data[\"day_of_week\"] = data[\"day_of_week\"].apply(\n",
    "            lambda x: 0 if x <= 3 else (1 if x == 4 else (2 if x == 5 else (3)))\n",
    "        )\n",
    "        data[\"week\"] = data[\"date\"].dt.isocalendar().week\n",
    "        data[\"week_sin\"] = np.sin(data[\"week\"] * (2 * np.pi / 53))\n",
    "        data[\"week_cos\"] = np.cos(data[\"week\"] * (2 * np.pi / 53))\n",
    "        data[\"year\"] = data[\"date\"].dt.year\n",
    "        data[\"cos_year\"] = np.cos(data[\"year\"] * (2 * np.pi) / 100)\n",
    "        data[\"sin_year\"] = np.sin(data[\"year\"] * (2 * np.pi) / 100)\n",
    "        data[[\"month\", \"day\", \"week\", \"year\"]] = data[\n",
    "            [\"month\", \"day\", \"week\", \"year\"]\n",
    "        ].astype(\"object\")\n",
    "        data[\"group\"] = (\n",
    "            (data[\"year\"] - 2020) * 48 + data[\"month\"] * 4 + data[\"day\"] // 7\n",
    "        )\n",
    "        data = pd.get_dummies(data, columns=[\"day_of_week\"], drop_first=True)\n",
    "        data[\"important_dates\"] = data[\"day_of_year\"].apply(\n",
    "            lambda x: (\n",
    "                x\n",
    "                if x\n",
    "                in [\n",
    "                    1,\n",
    "                    2,\n",
    "                    3,\n",
    "                    4,\n",
    "                    5,\n",
    "                    6,\n",
    "                    7,\n",
    "                    8,\n",
    "                    9,\n",
    "                    10,\n",
    "                    99,\n",
    "                    100,\n",
    "                    101,\n",
    "                    125,\n",
    "                    126,\n",
    "                    355,\n",
    "                    256,\n",
    "                    357,\n",
    "                    358,\n",
    "                    359,\n",
    "                    360,\n",
    "                    361,\n",
    "                    362,\n",
    "                    363,\n",
    "                    364,\n",
    "                    365,\n",
    "                ]\n",
    "                else 0\n",
    "            )\n",
    "        )\n",
    "        data.drop(columns=[\"day_of_year\"], inplace=True)\n",
    "\n",
    "        for day in range(24, 32):\n",
    "            data[f\"dec{day}\"] = (\n",
    "                (data.date.dt.day.eq(day) & data.date.dt.month.eq(12))\n",
    "                .astype(np.uint8)\n",
    "                .astype(\"object\")\n",
    "            )\n",
    "\n",
    "        alpha2 = dict(\n",
    "            zip(np.sort(data.country.unique()), [\"CA\", \"FI\", \"IT\", \"KE\", \"NO\", \"SG\"])\n",
    "        )\n",
    "        h = {\n",
    "            c: holidays.country_holidays(a, years=range(2010, 2020))\n",
    "            for c, a in alpha2.items()\n",
    "        }\n",
    "        data[\"is_holiday\"] = 0\n",
    "        for c in alpha2:\n",
    "            data.loc[data.country == c, \"is_holiday\"] = (\n",
    "                data.date.isin(h[c]).astype(int).astype(\"object\")\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            gdp_df = pd.read_csv(\"./datadown/gdp_df.csv\")#.drop('Unnamed: 0', axis = 1)\n",
    "        except:\n",
    "            print(\"no gdp data\")\n",
    "            gdp = []\n",
    "            for country in data.country.unique():\n",
    "                row = []\n",
    "                for year in range(2010,2020):\n",
    "                    row.append(self.get_gdp(country,year))\n",
    "                gdp.append(row)\n",
    "\n",
    "            gdp = np.array(gdp)\n",
    "            gdp /= np.sum(gdp,axis=0)\n",
    "\n",
    "            gdp_df = pd.DataFrame(gdp, index=data.country.unique(), columns=range(2010,2020))\n",
    "            gdp_df = gdp_df.reset_index().melt(id_vars = ['index']).rename({'index': 'country', 'variable': 'year', 'value': 'GDP'}, axis=1)\n",
    "        data = data.merge(gdp_df, how=\"left\", on=[\"year\", \"country\"])\n",
    "        return data\n",
    "\n",
    "    def log_transformation(self):\n",
    "        self.train[self.target] = np.log1p(self.train[self.target])\n",
    "        return self\n",
    "\n",
    "    def distribution(self):\n",
    "        print(Style.BRIGHT + Fore.GREEN + f\"\\nHistograms of distribution\\n\")\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "        ax_r, ax_n = axes\n",
    "\n",
    "        ax_r.set_title(\n",
    "            f\"{self.target} ($\\mu=$ {self.train_raw[self.target].mean():.2f} and $\\sigma=$ {self.train_raw[self.target].std():.2f} )\"\n",
    "        )\n",
    "        ax_r.hist(self.train_raw[self.target], bins=30, color=\"#3cb371\")\n",
    "        ax_r.axvline(self.train_raw[self.target].mean(), color=\"r\", label=\"Mean\")\n",
    "        ax_r.axvline(\n",
    "            self.train_raw[self.target].median(),\n",
    "            color=\"y\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"Median\",\n",
    "        )\n",
    "        ax_r.legend()\n",
    "\n",
    "        ax_n.set_title(\n",
    "            f\"{self.target} Normalized ($\\mu=$ {self.train_enc[self.target].mean():.2f} and $\\sigma=$ {self.train_enc[self.target].std():.2f} )\"\n",
    "        )\n",
    "        ax_n.hist(self.train_enc[self.target], bins=30, color=\"#3cb371\")\n",
    "        ax_n.axvline(self.train_enc[self.target].mean(), color=\"r\", label=\"Mean\")\n",
    "        ax_n.axvline(\n",
    "            self.train_enc[self.target].median(),\n",
    "            color=\"y\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"Median\",\n",
    "        )\n",
    "        ax_n.legend()\n",
    "\n",
    "    def remove_outliers(self):\n",
    "        Q1 = self.train[self.targets].quantile(0.25)\n",
    "        Q3 = self.train[self.targets].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_limit = Q1 - 1.5 * IQR\n",
    "        upper_limit = Q3 + 1.5 * IQR\n",
    "        self.train = self.train[\n",
    "            (self.train[self.targets] >= lower_limit)\n",
    "            & (self.train[self.targets] <= upper_limit)\n",
    "        ]\n",
    "        self.train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def scaler(self):\n",
    "        scaler = StandardScaler()\n",
    "        self.train[self.num_features] = scaler.fit_transform(\n",
    "            self.train[self.num_features]\n",
    "        )\n",
    "        self.test[self.num_features] = scaler.transform(self.test[self.num_features])\n",
    "        return self\n",
    "\n",
    "    def missing_values(self):\n",
    "        train_df_imputed = self.train.copy()\n",
    "        for year in train_df_imputed[\"year\"].unique():\n",
    "            target_ratio = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"country\"] == \"Norway\"),\n",
    "                \"GDP\",\n",
    "            ].values[0]\n",
    "            current_raito = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"country\"] == \"Canada\"),\n",
    "                \"GDP\",\n",
    "            ].values[0]\n",
    "            ratio_can = current_raito / target_ratio\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Canada\")\n",
    "                & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_can\n",
    "            ).values\n",
    "\n",
    "            current_ts = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Canada\")\n",
    "                & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "            ]\n",
    "            missing_ts_dates = current_ts.loc[current_ts[\"num_sold\"].isna(), \"date\"]\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Canada\")\n",
    "                & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year)\n",
    "                    & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_can\n",
    "            ).values\n",
    "\n",
    "            current_ts = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Canada\")\n",
    "                & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "            ]\n",
    "            missing_ts_dates = current_ts.loc[current_ts[\"num_sold\"].isna(), \"date\"]\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Canada\")\n",
    "                & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year)\n",
    "                    & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_can\n",
    "            ).values\n",
    "\n",
    "            current_raito = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"country\"] == \"Kenya\"),\n",
    "                \"GDP\",\n",
    "            ].values[0]\n",
    "            ratio_ken = current_raito / target_ratio\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_ken\n",
    "            ).values\n",
    "\n",
    "            current_ts = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "            ]\n",
    "            missing_ts_dates = current_ts.loc[current_ts[\"num_sold\"].isna(), \"date\"]\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Premium Sticker Mart\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year)\n",
    "                    & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_ken\n",
    "            ).values\n",
    "\n",
    "            current_ts = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "            ]\n",
    "            missing_ts_dates = current_ts.loc[current_ts[\"num_sold\"].isna(), \"date\"]\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Stickers for Less\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Holographic Goose\")\n",
    "                    & (train_df_imputed[\"year\"] == year)\n",
    "                    & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_ken\n",
    "            ).values\n",
    "\n",
    "            current_ts = train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                & (train_df_imputed[\"product\"] == \"Kerneler\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "            ]\n",
    "            missing_ts_dates = current_ts.loc[current_ts[\"num_sold\"].isna(), \"date\"]\n",
    "            train_df_imputed.loc[\n",
    "                (train_df_imputed[\"country\"] == \"Kenya\")\n",
    "                & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                & (train_df_imputed[\"product\"] == \"Kerneler\")\n",
    "                & (train_df_imputed[\"year\"] == year)\n",
    "                & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                \"num_sold\",\n",
    "            ] = (\n",
    "                train_df_imputed.loc[\n",
    "                    (train_df_imputed[\"country\"] == \"Norway\")\n",
    "                    & (train_df_imputed[\"store\"] == \"Discount Stickers\")\n",
    "                    & (train_df_imputed[\"product\"] == \"Kerneler\")\n",
    "                    & (train_df_imputed[\"year\"] == year)\n",
    "                    & (train_df_imputed[\"date\"].isin(missing_ts_dates)),\n",
    "                    \"num_sold\",\n",
    "                ]\n",
    "                * ratio_ken\n",
    "            ).values\n",
    "\n",
    "        train_df_imputed.loc[train_df_imputed.index == 23719, \"num_sold\"] = 4\n",
    "        train_df_imputed.loc[train_df_imputed.index == 207003, \"num_sold\"] = 195\n",
    "        self.train = train_df_imputed.drop(\"date\", axis=1)\n",
    "        self.test.drop(\"date\", axis=1, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def reduce_mem(self, df):\n",
    "\n",
    "        numerics = [\n",
    "            \"int16\",\n",
    "            \"int32\",\n",
    "            \"int64\",\n",
    "            \"float16\",\n",
    "            \"float32\",\n",
    "            \"float64\",\n",
    "            \"uint16\",\n",
    "            \"uint32\",\n",
    "            \"uint64\",\n",
    "        ]\n",
    "\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtypes\n",
    "\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if \"int\" in str(col_type):\n",
    "                    if c_min >= np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif (\n",
    "                        c_min >= np.iinfo(np.int16).min\n",
    "                        and c_max < np.iinfo(np.int16).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif (\n",
    "                        c_min >= np.iinfo(np.int32).min\n",
    "                        and c_max < np.iinfo(np.int32).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif (\n",
    "                        c_min >= np.iinfo(np.int64).min\n",
    "                        and c_max < np.iinfo(np.int64).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "                else:\n",
    "                    if (\n",
    "                        c_min >= np.finfo(np.float16).min\n",
    "                        and c_max < np.finfo(np.float16).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    if (\n",
    "                        c_min >= np.finfo(np.float32).min\n",
    "                        and c_max < np.finfo(np.float32).max\n",
    "                    ):\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_gdp(self, country, year):\n",
    "        alpha3 = {\n",
    "            \"Canada\": \"CAN\",\n",
    "            \"Finland\": \"FIN\",\n",
    "            \"Italy\": \"ITA\",\n",
    "            \"Kenya\": \"KEN\",\n",
    "            \"Norway\": \"NOR\",\n",
    "            \"Singapore\": \"SGP\",\n",
    "        }\n",
    "\n",
    "        url = \"https://api.worldbank.org/v2/country/{0}/indicator/NY.GDP.PCAP.CD?date={1}&format=json\".format(\n",
    "            alpha3[country], year\n",
    "        )\n",
    "        response = requests.get(url).json()\n",
    "        return response[1][0][\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:08:36.046773Z",
     "iopub.status.busy": "2025-01-17T10:08:36.046484Z",
     "iopub.status.idle": "2025-01-17T10:09:20.396762Z",
     "shell.execute_reply": "2025-01-17T10:09:20.395662Z",
     "shell.execute_reply.started": "2025-01-17T10:08:36.046749Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      "Histograms of distribution\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15 sec\n",
    "t = Transform()\n",
    "X, X_enc, y, test, test_enc, cat_features = t()\n",
    "# X, X_enc, y, test, test_enc = 0, 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>store</th>\n",
       "      <th>product</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>week</th>\n",
       "      <th>week_sin</th>\n",
       "      <th>week_cos</th>\n",
       "      <th>year</th>\n",
       "      <th>cos_year</th>\n",
       "      <th>sin_year</th>\n",
       "      <th>group</th>\n",
       "      <th>day_of_week_1</th>\n",
       "      <th>day_of_week_2</th>\n",
       "      <th>day_of_week_3</th>\n",
       "      <th>important_dates</th>\n",
       "      <th>dec24</th>\n",
       "      <th>dec25</th>\n",
       "      <th>dec26</th>\n",
       "      <th>dec27</th>\n",
       "      <th>dec28</th>\n",
       "      <th>dec29</th>\n",
       "      <th>dec30</th>\n",
       "      <th>dec31</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>-476</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>-476</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>-476</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>-476</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Discount Stickers</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201294</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>53</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>0.587891</td>\n",
       "      <td>-476</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230125</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Holographic Goose</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>-140</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230126</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>-140</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230127</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kaggle Tiers</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>-140</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230128</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>-140</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230129</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Premium Sticker Mart</td>\n",
       "      <td>Kerneler Dark Mode</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.118273</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>-140</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.231079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>230130 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country                 store             product quarter month   \n",
       "0          Canada     Discount Stickers   Holographic Goose       1     1  \\\n",
       "1          Canada     Discount Stickers              Kaggle       1     1   \n",
       "2          Canada     Discount Stickers        Kaggle Tiers       1     1   \n",
       "3          Canada     Discount Stickers            Kerneler       1     1   \n",
       "4          Canada     Discount Stickers  Kerneler Dark Mode       1     1   \n",
       "...           ...                   ...                 ...     ...   ...   \n",
       "230125  Singapore  Premium Sticker Mart   Holographic Goose       4    12   \n",
       "230126  Singapore  Premium Sticker Mart              Kaggle       4    12   \n",
       "230127  Singapore  Premium Sticker Mart        Kaggle Tiers       4    12   \n",
       "230128  Singapore  Premium Sticker Mart            Kerneler       4    12   \n",
       "230129  Singapore  Premium Sticker Mart  Kerneler Dark Mode       4    12   \n",
       "\n",
       "        month_sin  month_cos day   day_sin   day_cos week  week_sin  week_cos   \n",
       "0             0.5   0.866211   1  0.201294  0.979492   53      -0.0       1.0  \\\n",
       "1             0.5   0.866211   1  0.201294  0.979492   53      -0.0       1.0   \n",
       "2             0.5   0.866211   1  0.201294  0.979492   53      -0.0       1.0   \n",
       "3             0.5   0.866211   1  0.201294  0.979492   53      -0.0       1.0   \n",
       "4             0.5   0.866211   1  0.201294  0.979492   53      -0.0       1.0   \n",
       "...           ...        ...  ..       ...       ...  ...       ...       ...   \n",
       "230125       -0.0   1.000000  31 -0.000000  1.000000   52 -0.118273  0.992981   \n",
       "230126       -0.0   1.000000  31 -0.000000  1.000000   52 -0.118273  0.992981   \n",
       "230127       -0.0   1.000000  31 -0.000000  1.000000   52 -0.118273  0.992981   \n",
       "230128       -0.0   1.000000  31 -0.000000  1.000000   52 -0.118273  0.992981   \n",
       "230129       -0.0   1.000000  31 -0.000000  1.000000   52 -0.118273  0.992981   \n",
       "\n",
       "        year  cos_year  sin_year group day_of_week_1 day_of_week_2   \n",
       "0       2010  0.809082  0.587891  -476          True         False  \\\n",
       "1       2010  0.809082  0.587891  -476          True         False   \n",
       "2       2010  0.809082  0.587891  -476          True         False   \n",
       "3       2010  0.809082  0.587891  -476          True         False   \n",
       "4       2010  0.809082  0.587891  -476          True         False   \n",
       "...      ...       ...       ...   ...           ...           ...   \n",
       "230125  2016  0.535645  0.844238  -140         False          True   \n",
       "230126  2016  0.535645  0.844238  -140         False          True   \n",
       "230127  2016  0.535645  0.844238  -140         False          True   \n",
       "230128  2016  0.535645  0.844238  -140         False          True   \n",
       "230129  2016  0.535645  0.844238  -140         False          True   \n",
       "\n",
       "       day_of_week_3  important_dates dec24 dec25 dec26 dec27 dec28 dec29   \n",
       "0              False                1     0     0     0     0     0     0  \\\n",
       "1              False                1     0     0     0     0     0     0   \n",
       "2              False                1     0     0     0     0     0     0   \n",
       "3              False                1     0     0     0     0     0     0   \n",
       "4              False                1     0     0     0     0     0     0   \n",
       "...              ...              ...   ...   ...   ...   ...   ...   ...   \n",
       "230125         False                0     0     0     0     0     0     0   \n",
       "230126         False                0     0     0     0     0     0     0   \n",
       "230127         False                0     0     0     0     0     0     0   \n",
       "230128         False                0     0     0     0     0     0     0   \n",
       "230129         False                0     0     0     0     0     0     0   \n",
       "\n",
       "       dec30 dec31 is_holiday       GDP  \n",
       "0          0     0          1  0.178345  \n",
       "1          0     0          1  0.178345  \n",
       "2          0     0          1  0.178345  \n",
       "3          0     0          1  0.178345  \n",
       "4          0     0          1  0.178345  \n",
       "...      ...   ...        ...       ...  \n",
       "230125     0     1          0  0.231079  \n",
       "230126     0     1          0  0.231079  \n",
       "230127     0     1          0  0.231079  \n",
       "230128     0     1          0  0.231079  \n",
       "230129     0     1          0  0.231079  \n",
       "\n",
       "[230130 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.to_csv(\"./dataup/y.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "X[cat_features].apply(\"nunique\").tolist(), X_enc[cat_features].apply(\"nunique\").tolist(), test[cat_features].apply(\"nunique\").tolist(), test_enc[cat_features].apply(\"nunique\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cat_features_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = {}\n",
    "# for  j in ['X', \"X_enc\", 'y', \"test\", \"test_enc\",]:\n",
    "#     s[j] = pd.read_csv(f'./pgs51/dataup/data_{j}.csv').drop(\"Unnamed: 0\", axis = 1)\n",
    "# s.keys()\n",
    "# # X = s['X']\n",
    "# # X_enc = s['X_enc']\n",
    "# # y = s['y']\n",
    "# # test = s['test']\n",
    "# # test_enc = s['test_enc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:09:20.398207Z",
     "iopub.status.busy": "2025-01-17T10:09:20.397873Z",
     "iopub.status.idle": "2025-01-17T10:09:20.776168Z",
     "shell.execute_reply": "2025-01-17T10:09:20.775091Z",
     "shell.execute_reply.started": "2025-01-17T10:09:20.398166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import contextlib, io\n",
    "import ydf; ydf.verbose(2)\n",
    "from ydf import GradientBoostedTreesLearner\n",
    "\n",
    "def YDFRegressor(learner_class):\n",
    "\n",
    "    class YDFXRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "        def __init__(self, params={}):\n",
    "            self.params = params\n",
    "\n",
    "        def fit(self, X, y):\n",
    "            assert isinstance(X, pd.DataFrame)\n",
    "            assert isinstance(y, pd.Series)\n",
    "            target = y.name\n",
    "            params = self.params.copy()\n",
    "            params['label'] = target\n",
    "            params['task'] = ydf.Task.REGRESSION\n",
    "            X = pd.concat([X, y], axis=1)\n",
    "            with contextlib.redirect_stderr(io.StringIO()), contextlib.redirect_stdout(io.StringIO()):\n",
    "                self.model = learner_class(**params).train(X)\n",
    "            return self\n",
    "\n",
    "        def predict(self, X):\n",
    "            assert isinstance(X, pd.DataFrame)\n",
    "            with contextlib.redirect_stderr(io.StringIO()), contextlib.redirect_stdout(io.StringIO()):\n",
    "                return self.model.predict(X)\n",
    "\n",
    "    return YDFXRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
    "    embs = []\n",
    "    for j in range(len(cat_features)):\n",
    "        e = layers.Embedding(t.cat_features_card[j], int(np.ceil(np.sqrt(t.cat_features_card[j]))))\n",
    "        x = e(x_input_cats[:,j])\n",
    "        x = layers.Flatten()(x)\n",
    "        embs.append(x)\n",
    "        \n",
    "    x_input_nums = layers.Input(shape=(len(t.num_features),))\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums]) \n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[x_input_cats,x_input_nums], outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM-based model\n",
    "def build_model_lstm():\n",
    "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
    "    embs = []\n",
    "    for j in range(len(cat_features)):\n",
    "        e = layers.Embedding(t.cat_features_card[j], int(np.ceil(np.sqrt(t.cat_features_card[j]))))\n",
    "        x = e(x_input_cats[:,j])\n",
    "        x = layers.Flatten()(x)\n",
    "        embs.append(x)\n",
    "        \n",
    "    x_input_nums = layers.Input(shape=(len(t.num_features),))\n",
    "    \n",
    "    # Combine embeddings and numerical features\n",
    "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
    "    # Reshape for LSTM (adding time dimension)\n",
    "    x = layers.Reshape((1, -1))(x)\n",
    "    # LSTM layers\n",
    "    x = layers.LSTM(256, return_sequences=True)(x)\n",
    "    x = layers.LSTM(128)(x)\n",
    "    # Dense layers\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[x_input_cats, x_input_nums], outputs=x)\n",
    "    return model\n",
    "\n",
    "# Self-attention based model\n",
    "def build_model_attention():\n",
    "    x_input_cats = layers.Input(shape=(len(cat_features),))\n",
    "    embs = []\n",
    "    for j in range(len(cat_features)):\n",
    "        e = layers.Embedding(t.cat_features_card[j], int(np.ceil(np.sqrt(t.cat_features_card[j]))))\n",
    "        x = e(x_input_cats[:,j])\n",
    "        x = layers.Flatten()(x)\n",
    "        embs.append(x)\n",
    "        \n",
    "    x_input_nums = layers.Input(shape=(len(t.num_features),))\n",
    "    # Combine embeddings and numerical features\n",
    "    x = layers.Concatenate(axis=-1)(embs+[x_input_nums])\n",
    "    # Multi-head self attention\n",
    "    def attention_block(x, num_heads=4):\n",
    "        dim = x.shape[-1]\n",
    "        hidden_dim = dim // num_heads\n",
    "        # Reshape for multi-head attention\n",
    "        x = layers.Reshape((1, -1))(x)\n",
    "        # Self attention layer\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=hidden_dim\n",
    "        )(x, x)\n",
    "        \n",
    "        # Add & Norm\n",
    "        x = layers.Add()([x, attention_output])\n",
    "        x = layers.LayerNormalization()(x)\n",
    "        \n",
    "        # Flatten back\n",
    "        x = layers.Flatten()(x)\n",
    "        return x\n",
    "    # Apply attention\n",
    "    x = attention_block(x)\n",
    "    # Dense layers\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(1)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=[x_input_cats, x_input_nums], outputs=x)\n",
    "    return model\n",
    "models = {\n",
    "    \"NN1\": [build_model, True],\n",
    "    \"NN2\": [build_model_lstm, True],\n",
    "    \"NN3\": [build_model_attention, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:09:20.788579Z",
     "iopub.status.busy": "2025-01-17T10:09:20.788175Z",
     "iopub.status.idle": "2025-01-17T10:09:20.82007Z",
     "shell.execute_reply": "2025-01-17T10:09:20.818595Z",
     "shell.execute_reply.started": "2025-01-17T10:09:20.788544Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'NN': [_,\n",
    "    #        True],\n",
    "    # 'CAT': [CatBoostRegressor(**{'verbose': 0,\n",
    "    #                              'random_state': Config.state,\n",
    "    #                              'cat_features': cat_features,\n",
    "    #                              'early_stopping_rounds': Config.early_stop,\n",
    "    #                              'eval_metric': \"RMSE\",\n",
    "    #                              'n_estimators' : 2000,\n",
    "    #                              'depth': 3,\n",
    "    #                              'min_data_in_leaf': 96,\n",
    "    #                              'l2_leaf_reg': 8.972890275248485,\n",
    "    #                              'bagging_temperature': 0.18658249870341914, \n",
    "    #                              'random_strength': 0.14106593468982453,\n",
    "    #                              'learning_rate': 0.01,\n",
    "    #                             }),\n",
    "    #         True],\n",
    "    # 'CAT3': [CatBoostRegressor(**{'verbose': 0,\n",
    "    #                               'random_state': Config.state,\n",
    "    #                               'cat_features': cat_features,\n",
    "    #                               'early_stopping_rounds': Config.early_stop,\n",
    "    #                               'eval_metric': \"MAPE\",\n",
    "    #                               'n_estimators' : 2000,\n",
    "    #                               'learning_rate': 0.01,\n",
    "    #                               'depth': 8,\n",
    "    #                               'min_data_in_leaf': 99,\n",
    "    #                               'l2_leaf_reg': 7.7324870113971125, \n",
    "    #                               'bagging_temperature': 0.003232535109945575, \n",
    "    #                               'random_strength': 0.12145610701952099,\n",
    "    #                              }),\n",
    "    #          True],\n",
    "    # 'CAT5': [CatBoostRegressor(**{'depth': 7,\n",
    "    #                               'min_data_in_leaf': 59,\n",
    "    #                               'l2_leaf_reg': 6.485681470975604, \n",
    "    #                               'bagging_temperature': 0.728613892125684,\n",
    "    #                               'random_strength': 0.3565990691132947,\n",
    "    #                               'verbose': 0,\n",
    "    #                               'random_state': Config.state,\n",
    "    #                               'cat_features': cat_features,\n",
    "    #                               'early_stopping_rounds': Config.early_stop,\n",
    "    #                               'eval_metric': \"MAPE\",\n",
    "    #                               'n_estimators' : 2000,\n",
    "    #                               'learning_rate': 0.01,\n",
    "    #                               \"task_type\": \"cpu\",\n",
    "    #                              }),\n",
    "    #          True],\n",
    "    # 'CAT6': [CatBoostRegressor(**{'depth': 10,\n",
    "    #                               'min_data_in_leaf': 67,\n",
    "    #                               'l2_leaf_reg': 0.010658988402410939,\n",
    "    #                               'bagging_temperature': 0.7381549501573549,\n",
    "    #                               'random_strength': 0.10057316762567874,\n",
    "    #                               'verbose': 0,\n",
    "    #                               'random_state': Config.state,\n",
    "    #                               'cat_features': cat_features,\n",
    "    #                               'early_stopping_rounds': Config.early_stop,\n",
    "    #                               'eval_metric': \"MAPE\",\n",
    "    #                               'n_estimators' : 2000,\n",
    "    #                               'learning_rate': 0.01,\n",
    "    #                               'bootstrap_type': 'Poisson',\n",
    "    #                               \"task_type\": \"cpu\",\n",
    "    #                              }),\n",
    "    #          True],\n",
    "    # 'XGB2': [XGBRegressor(**{'tree_method': 'hist',\n",
    "    #                          'n_estimators': 2000,\n",
    "    #                          'objective': 'reg:squarederror',\n",
    "    #                          'random_state': Config.state,\n",
    "    #                          'enable_categorical': True,\n",
    "    #                          'verbosity': 0,\n",
    "    #                          'early_stopping_rounds': Config.early_stop,\n",
    "    #                          'eval_metric': 'rmse',\n",
    "    #                          'booster': 'gbtree', \n",
    "    #                          'max_depth': 3,\n",
    "    #                          'min_child_weight': 16,\n",
    "    #                          'subsample': 0.8172380854733758, \n",
    "    #                          'reg_alpha': 0.2734696712123178, \n",
    "    #                          'reg_lambda': 0.5865768393479154,\n",
    "    #                          'colsample_bytree': 0.9766164536195251,\n",
    "    #                          'n_jobs': -1,\n",
    "    #                          'learning_rate': 0.01,\n",
    "    #                          'n_jobs': -1\n",
    "    #                         }),\n",
    "    #         True],\n",
    "    # 'XGB3': [XGBRegressor(**{'tree_method': 'hist',\n",
    "    #                          'n_estimators': 2000,\n",
    "    #                          'learning_rate': 0.01,\n",
    "    #                          'objective': 'reg:squarederror',\n",
    "    #                          'random_state': Config.state,\n",
    "    #                          'enable_categorical': True,\n",
    "    #                          'verbosity': 0,\n",
    "    #                          'early_stopping_rounds': Config.early_stop,\n",
    "    #                          'eval_metric': 'mape',\n",
    "    #                          'booster': 'gbtree',\n",
    "    #                          'max_depth': 3,\n",
    "    #                          'min_child_weight': 12,\n",
    "    #                          'subsample': 0.7720667996291699, \n",
    "    #                          'reg_alpha': 0.07869714859026081, \n",
    "    #                          'reg_lambda': 0.9577219578640989, \n",
    "    #                          'colsample_bytree': 0.9728085969282255, \n",
    "    #                          'n_jobs': -1\n",
    "    #                        }),\n",
    "    #     True],\n",
    "    # 'XGB4': [XGBRegressor(**{'booster': 'gbtree',\n",
    "    #                          'max_depth': 3,\n",
    "    #                          'min_child_weight': 12,\n",
    "    #                          'subsample': 0.800221370346261,\n",
    "    #                          'reg_alpha': 0.4571249607822852,\n",
    "    #                          'reg_lambda': 0.6572354640280187,\n",
    "    #                          'colsample_bytree': 0.9982441671154363,\n",
    "    #                          'n_jobs': -1,\n",
    "    #                          'tree_method': 'hist',\n",
    "    #                          'n_estimators': 3000,\n",
    "    #                          'learning_rate': 0.01,\n",
    "    #                          'objective': 'reg:squarederror',\n",
    "    #                          'random_state': Config.state,\n",
    "    #                          'enable_categorical': True,\n",
    "    #                          'verbosity': 0,\n",
    "    #                          'early_stopping_rounds': Config.early_stop,\n",
    "    #                          'eval_metric': 'mape',\n",
    "    #                          'booster': 'gbtree',\n",
    "    #                          \"device\": \"cuda\",\n",
    "    #                         }),\n",
    "    #          True],\n",
    "    # 'XGB5': [XGBRegressor(**{'booster': 'gbtree',\n",
    "    #                          'max_depth': 3,\n",
    "    #                          'min_child_weight': 19,\n",
    "    #                          'subsample': 0.8065343833518619,\n",
    "    #                          'reg_alpha': 0.3577049940509907,\n",
    "    #                          'reg_lambda': 0.8560297700871249,\n",
    "    #                          'colsample_bytree': 0.9866141987520272,\n",
    "    #                          'objective': 'reg:squarederror',\n",
    "    #                          'n_jobs': -1,\n",
    "    #                          'tree_method': 'hist',\n",
    "    #                          'n_estimators': 3000,\n",
    "    #                          'learning_rate': 0.01,\n",
    "    #                          'random_state': Config.state,\n",
    "    #                          'enable_categorical': True,\n",
    "    #                          'verbosity': 0,\n",
    "    #                          'early_stopping_rounds': Config.early_stop,\n",
    "    #                          'eval_metric': 'mape', \n",
    "    #                          \"device\": \"cuda\",\n",
    "    #                          }),\n",
    "    #          True],\n",
    "    'LGBM2': [LGBMRegressor(**{'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'gbdt',\n",
    "                               'eval_metric': 'rmse',\n",
    "                               'objective': 'regression_l2',\n",
    "                               'n_estimators': 5000,\n",
    "                               'max_depth': 13, \n",
    "                               'num_leaves': 891, \n",
    "                               'min_child_samples': 16,\n",
    "                               'min_child_weight': 11,\n",
    "                               'colsample_bytree': 0.48639630433139497,\n",
    "                               'reg_alpha': 0.45496760242817474,\n",
    "                               'reg_lambda': 0.9669296995303693,\n",
    "                               'learning_rate': 0.01\n",
    "                              }),\n",
    "             True],\n",
    "    'LGBM3': [LGBMRegressor(**{'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'gbdt',\n",
    "                               'eval_metric': 'rmse',\n",
    "                               'objective': 'regression_l2',\n",
    "                               'n_estimators': 2000,\n",
    "                               'max_depth': 6, \n",
    "                               'num_leaves': 328,\n",
    "                               'min_child_samples': 10,\n",
    "                               'min_child_weight': 16,\n",
    "                               'colsample_bytree': 0.4893394195489041,\n",
    "                               'reg_alpha': 0.18334253987924942,\n",
    "                               'reg_lambda': 0.8328414321738785,\n",
    "                               'learning_rate': 0.01\n",
    "                              }),\n",
    "             True],\n",
    "    'LGBM4': [LGBMRegressor(**{'objective': 'regression_l2',\n",
    "                               'metric': 'mape', \n",
    "                               'max_depth': 12, \n",
    "                               'num_leaves': 878,\n",
    "                               'min_child_samples': 29,\n",
    "                               'min_child_weight': 14,\n",
    "                               'colsample_bytree': 0.49788260207319734, \n",
    "                               'reg_alpha': 0.4747476308475839, \n",
    "                               'reg_lambda': 0.6960820486441526,\n",
    "                               'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'gbdt',\n",
    "                               'eval_metric': 'mape',\n",
    "                               'objective': 'regression_l2',\n",
    "                               'n_estimators': 3000,\n",
    "                               'learning_rate': 0.01,\n",
    "                               }),\n",
    "              True],\n",
    "    'LGBM5': [LGBMRegressor(**{'objective': 'regression_l2',\n",
    "                               'metric': 'mape', \n",
    "                               'max_depth': 7,\n",
    "                               'num_leaves': 123, \n",
    "                               'min_child_samples': 21,\n",
    "                               'min_child_weight': 24,\n",
    "                               'colsample_bytree': 0.3641261996760593, \n",
    "                               'reg_alpha': 0.03632800166349373, \n",
    "                               'reg_lambda': 0.5287861861476272,\n",
    "                               'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'gbdt',\n",
    "                               'n_estimators': 3000,\n",
    "                               'learning_rate': 0.01,\n",
    "                               }),\n",
    "              True],\n",
    "    'LGBM6': [LGBMRegressor(**{'objective': 'regression_l2',\n",
    "                               'metric': 'mape',\n",
    "                               'max_depth': 6,\n",
    "                               'num_leaves': 502,\n",
    "                               'min_child_samples': 23,\n",
    "                               'min_child_weight': 18, \n",
    "                               'colsample_bytree': 0.4714820876493163, \n",
    "                               'reg_alpha': 0.054972003081022576, \n",
    "                               'reg_lambda': 0.5774608955362155,\n",
    "                               'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'goss',\n",
    "                               'n_estimators': 3000,\n",
    "                               'learning_rate': 0.01,\n",
    "                              }),\n",
    "             True],\n",
    "    'LGBM7': [LGBMRegressor(**{'objective': 'regression_l2', \n",
    "                               'metric': 'mape',\n",
    "                               'max_depth': 14,\n",
    "                               'num_leaves': 279,\n",
    "                               'min_child_samples': 7,\n",
    "                               'min_child_weight': 24, \n",
    "                               'colsample_bytree': 0.43218993309765835,\n",
    "                               'reg_alpha': 0.42757392987472964,\n",
    "                               'reg_lambda': 0.9039762787446107,\n",
    "                               'random_state': Config.state,\n",
    "                               'early_stopping_round': Config.early_stop,\n",
    "                               'categorical_feature': cat_features,\n",
    "                               'verbose': -1,\n",
    "                               'boosting_type': 'goss',\n",
    "                               'n_estimators': 3000,\n",
    "                               'learning_rate': 0.01,\n",
    "                               }),\n",
    "              True],\n",
    "    'Ridge': [Ridge(tol=1e-2, max_iter=1000000,\n",
    "                    random_state=Config.state),\n",
    "              False],\n",
    "    'BRidge': [BayesianRidge(tol=1e-2, max_iter=1000000),\n",
    "              False],\n",
    "    'LR': [LinearRegression(),\n",
    "              False],\n",
    "    'HGB': [HistGradientBoostingRegressor(**{'max_depth': 4,\n",
    "                                             'loss': 'squared_error',\n",
    "                                             'l2_regularization': 0.014082438341668873,\n",
    "                                             'min_samples_leaf': 39,\n",
    "                                             'max_leaf_nodes': 25,\n",
    "                                             'learning_rate': 0.01,\n",
    "                                             'max_iter': 2000,\n",
    "                                             'random_state': Config.state,\n",
    "                                             'early_stopping': Config.early_stop,\n",
    "                                            }),\n",
    "              False],\n",
    "    'HGB2': [HistGradientBoostingRegressor(**{'max_depth': 4,\n",
    "                                              'loss': 'squared_error',\n",
    "                                              'l2_regularization': 1.0294569289519551e-05,\n",
    "                                              'min_samples_leaf': 12, \n",
    "                                              'max_leaf_nodes': 26,\n",
    "                                              'learning_rate': 0.01,\n",
    "                                              'max_iter': 2000,\n",
    "                                              'random_state': Config.state,\n",
    "                                              'early_stopping': Config.early_stop,\n",
    "                                             }),\n",
    "             False],\n",
    "    'HGB3': [HistGradientBoostingRegressor(**{'max_depth': 13, \n",
    "                                              'loss': 'squared_error',\n",
    "                                              'l2_regularization': 0.05253480068908677,\n",
    "                                              'min_samples_leaf': 19,\n",
    "                                              'max_leaf_nodes': 40,\n",
    "                                              'learning_rate': 0.01,\n",
    "                                              'max_iter': 3000,\n",
    "                                              'random_state': Config.state,\n",
    "                                              'early_stopping': Config.early_stop,\n",
    "                                             }),\n",
    "             False],\n",
    "    'HGB4': [HistGradientBoostingRegressor(**{'max_depth': 4, \n",
    "                                              'loss': 'squared_error', \n",
    "                                              'l2_regularization': 1.3248236291502028e-09,\n",
    "                                              'min_samples_leaf': 39,\n",
    "                                              'max_leaf_nodes': 29,\n",
    "                                              'learning_rate': 0.01,\n",
    "                                              'max_iter': 3000,\n",
    "                                              'random_state': Config.state,\n",
    "                                              'early_stopping': Config.early_stop,\n",
    "                                             }),\n",
    "             False],\n",
    "    'YDF': [YDFRegressor(GradientBoostedTreesLearner)({'num_trees': 1000,\n",
    "                                                       'max_depth': 13,\n",
    "                                                       }),\n",
    "            False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:12:01.486652Z",
     "iopub.status.busy": "2025-01-17T10:12:01.48615Z",
     "iopub.status.idle": "2025-01-17T10:12:01.524352Z",
     "shell.execute_reply": "2025-01-17T10:12:01.523344Z",
     "shell.execute_reply.started": "2025-01-17T10:12:01.486615Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModel\u001b[39;00m(\u001b[43mConfig\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, X_enc, y, test, test_enc, models):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "class Model(Config):\n",
    "    \n",
    "    def __init__(self, X, X_enc, y, test, test_enc, models):\n",
    "        self.y = y\n",
    "        self.models = models\n",
    "        self.scores = pd.DataFrame(columns=['Score'])\n",
    "        self.OOF_preds = pd.DataFrame()\n",
    "        self.TEST_preds = pd.DataFrame()\n",
    "        self.folds = GroupKFold(n_splits=self.n_splits)\n",
    "        self.model = None\n",
    "        self.model_dir = './pgs51/models/'\n",
    "\n",
    "    def train(self):      \n",
    "        \n",
    "        for model_name, [model, training] in tqdm(self.models.items()):\n",
    "            \n",
    "            if training:\n",
    "                print('='*20)\n",
    "                print(model_name)\n",
    "                if any(model in model_name for model in ['LGBM', 'CAT', 'XGB']):\n",
    "                    self.X = X\n",
    "                    self.test = test\n",
    " \n",
    "                else:\n",
    "                    self.X = X_enc\n",
    "                    self.test = test_enc\n",
    "                    \n",
    "                if 'NN' in model_name:\n",
    "                    for n_fold, (train_id, valid_id) in enumerate(self.folds.split(self.X, self.y, groups = X['year'])):\n",
    "\n",
    "                        X_train_cats = self.X.loc[train_id, cat_features]\n",
    "                        X_train_nums = self.X.loc[train_id, t.num_features]\n",
    "                        y_train = self.y.loc[train_id].values\n",
    "\n",
    "                        X_val_cats = self.X.loc[valid_id, cat_features]\n",
    "                        X_val_nums = self.X.loc[valid_id, t.num_features]\n",
    "                        y_val = self.y.loc[valid_id]\n",
    "\n",
    "                        X_test_cats = self.test[cat_features]\n",
    "                        X_test_nums = self.test[t.num_features]\n",
    "        \n",
    "                        oof_preds = pd.DataFrame(columns=[model_name], index=X_val_cats.index)\n",
    "                        test_preds = pd.DataFrame(columns=[model_name], index=test.index)\n",
    "                        print(f'Fold {n_fold+1}')\n",
    "                        \n",
    "                        model = build_model()                        \n",
    "                        keras.utils.set_random_seed(self.state)\n",
    "                        optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "                        model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "                        model.fit([X_train_cats,X_train_nums], y_train, \n",
    "                                  validation_data=([X_val_cats, X_val_nums], y_val),\n",
    "                                  epochs=20,\n",
    "                                  batch_size=1000,\n",
    "                                  callbacks=[keras.callbacks.ReduceLROnPlateau(patience=1),\n",
    "                                             keras.callbacks.EarlyStopping(patience=3)\n",
    "                                            ])\n",
    "                        \n",
    "                        y_pred_val = model.predict([X_val_cats, X_val_nums])\n",
    "                        print(X_train_cats.shape, X_train_nums.shape)\n",
    "                        print(X_test_cats.shape, X_test_nums.shape)\n",
    "                        test_pred = model.predict([X_test_cats, X_test_nums])\n",
    "                        \n",
    "                        score = mean_absolute_percentage_error(y_val, y_pred_val)\n",
    "                        print(score)\n",
    "                        self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = score\n",
    "                        \n",
    "                        oof_preds[model_name] = y_pred_val\n",
    "                        test_preds[model_name] = test_pred\n",
    "\n",
    "                        self.OOF_preds  = pd.concat([self.OOF_preds, oof_preds], axis = 0, ignore_index = False)\n",
    "                        self.TEST_preds = pd.concat([self.TEST_preds, test_preds], axis = 0, ignore_index = False)\n",
    "                                    \n",
    "                        # Save the model to a file locally\n",
    "                        model_save_path = f\"{self.model_dir}/{model_name}_fold{n_fold+1}.h5\"\n",
    "                        model.save(model_save_path)\n",
    "                else:\n",
    "                    for n_fold, (train_id, valid_id) in enumerate(self.folds.split(self.X, self.y, groups = self.X['year'])):\n",
    "                        X_train, y_train = self.X.iloc[train_id], self.y.iloc[train_id]\n",
    "                        X_val, y_val = self.X.iloc[valid_id], self.y.iloc[valid_id]\n",
    "\n",
    "                        oof_preds = pd.DataFrame(columns=[model_name], index=X_val.index)\n",
    "                        test_preds = pd.DataFrame(columns=[model_name], index=test.index)\n",
    "                        print(f'Fold {n_fold+1}')\n",
    "\n",
    "                        if \"XGB\" in model_name:\n",
    "                            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "                            self.model = model\n",
    "                            # Save XGBoost model\n",
    "                            model_save_path = f\"{self.model_dir}/{model_name}_fold{n_fold+1}.json\"\n",
    "                            model.save_model(model_save_path)\n",
    "                            print(f\"XGBoost model saved to {model_save_path}\")\n",
    "                \n",
    "                        elif \"CAT\" in model_name:\n",
    "                            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "                            # Save CatBoost model\n",
    "                            self.model = model\n",
    "                            model_save_path = f\"{self.model_dir}/{model_name}_fold{n_fold+1}.cbm\"\n",
    "                            model.save_model(model_save_path)\n",
    "                            print(f\"CatBoost model saved to {model_save_path}\")\n",
    "                \n",
    "                        elif \"LGBM\" in model_name:\n",
    "                            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], callbacks=[log_evaluation(0), early_stopping(self.early_stop, verbose=False)])\n",
    "                            self.model = model\n",
    "                            # Save LightGBM model\n",
    "                            model_save_path = f\"{self.model_dir}/{model_name}_fold{n_fold+1}.txt\"\n",
    "                            model.booster_.save_model(model_save_path)  # Use the booster_ attribute\n",
    "                            print(f\"LightGBM model saved to {model_save_path}\")\n",
    "                \n",
    "                        else:\n",
    "                            model.fit(X_train, y_train)\n",
    "                            # Save general model (if applicable, e.g., a neural network)\n",
    "                            self.model = model\n",
    "                            model_save_path = f\"{self.model_dir}/{model_name}_fold{n_fold+1}.h5\"\n",
    "                            model.save(model_save_path)\n",
    "                            print(f\"Model saved to {model_save_path}\")\n",
    "\n",
    "                        y_pred_val = model.predict(X_val)\n",
    "                        test_pred = model.predict(self.test)\n",
    "                       \n",
    "                        score = mean_absolute_percentage_error(np.expm1(y_val), np.expm1(y_pred_val))\n",
    "                        print(score)\n",
    "                        self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = score\n",
    "\n",
    "                        oof_preds[model_name] = y_pred_val\n",
    "                        test_preds[model_name] = test_pred\n",
    "                        self.OOF_preds = pd.concat([self.OOF_preds, oof_preds], axis = 0, ignore_index = False)\n",
    "                        self.TEST_preds = pd.concat([self.TEST_preds, test_preds], axis = 0, ignore_index = False)\n",
    "\n",
    "                self.OOF_preds = self.OOF_preds.groupby(level=0).mean()\n",
    "                self.TEST_preds = self.TEST_preds.groupby(level=0).mean()\n",
    "\n",
    "                self.OOF_preds[f'{model_name}'].to_csv(f'{model_name}_oof.csv', index=False)\n",
    "                self.TEST_preds[f'{model_name}'].to_csv(f'{model_name}_test.csv', index=False)\n",
    "            \n",
    "            else:\n",
    "                self.OOF_preds[f'{model_name}'] = pd.read_csv(f'/kaggle/input/sticker-models/{model_name}_oof.csv')\n",
    "                self.TEST_preds[f'{model_name}'] = pd.read_csv(f'/kaggle/input/sticker-models/{model_name}_test.csv')\n",
    "                \n",
    "                for n_fold, (train_id, valid_id) in enumerate(self.folds.split(self.OOF_preds[f'{model_name}'], self.y, groups = X['year'])):\n",
    "                    y_pred_val, y_val = self.OOF_preds[f'{model_name}'].iloc[valid_id], self.y.iloc[valid_id]\n",
    "                    self.scores.loc[f'{model_name}', f'Fold {n_fold+1}'] = mean_absolute_percentage_error(np.expm1(y_val), np.expm1(y_pred_val))\n",
    "                    \n",
    "            self.scores.loc[f'{model_name}', 'Score'] = self.scores.loc[f'{model_name}'][1:].mean()\n",
    "        self.scores.loc['Ensemble'], self.OOF_preds[\"Ensemble\"], self.TEST_preds[\"Ensemble\"] = self.ensemble(self.OOF_preds, self.y, self.TEST_preds)\n",
    "        self.scores = self.scores.sort_values('Score')\n",
    "\n",
    "        self.result()\n",
    "\n",
    "        return self.TEST_preds\n",
    "    \n",
    "    def ensemble(self, X, y, test):\n",
    "        scores = []\n",
    "        oof_pred = np.zeros(X.shape[0])\n",
    "        test_pred = np.zeros(test.shape[0])\n",
    "        model = BayesianRidge()\n",
    "        kf = KFold(n_splits=self.n_splits, random_state=self.state, shuffle=True)\n",
    "        \n",
    "        for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred_probs = model.predict(X_val)\n",
    "            oof_pred[val_idx] = y_pred_probs\n",
    "            test_pred += model.predict(test) / self.n_splits\n",
    "            \n",
    "            score = mean_absolute_percentage_error(np.expm1(y_val), np.expm1(y_pred_probs))\n",
    "            scores.append(score)\n",
    "                   \n",
    "        return np.mean(scores), oof_pred, test_pred\n",
    "    \n",
    "    def result(self):\n",
    "               \n",
    "        plt.figure(figsize=(14, 6))\n",
    "        colors = ['#3cb371' if i != 'Ensemble' else 'r' for i in self.scores.Score.index]\n",
    "        hbars = plt.barh(self.scores.index, self.scores.Score, color=colors, height=0.8)\n",
    "        plt.bar_label(hbars, fmt='%.5f')\n",
    "        plt.ylabel('Models')\n",
    "        plt.xlabel('Score')              \n",
    "        plt.show()\n",
    "\n",
    "        y = np.expm1(self.y).sort_index()\n",
    "        self.OOF_preds['Ensemble'] = np.expm1(self.OOF_preds['Ensemble']).sort_index()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        axes[0].scatter(y, self.OOF_preds['Ensemble'], alpha=0.5, s=15, edgecolors='#3cb371')\n",
    "        axes[0].plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
    "        axes[0].set_xlabel('Actual')\n",
    "        axes[0].set_ylabel('Predicted')\n",
    "        axes[0].set_title('Actual vs. Predicted')\n",
    "\n",
    "        axes[1].scatter(self.OOF_preds['Ensemble'], y - self.OOF_preds['Ensemble'], alpha=0.5, s=15, edgecolors='#3cb371')\n",
    "        axes[1].axhline(y=0, color='black', linestyle='--', lw=2)\n",
    "        axes[1].set_xlabel('Predicted Values')\n",
    "        axes[1].set_ylabel('Residuals')\n",
    "        axes[1].set_title('Residual Plot')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:16:06.410238Z",
     "iopub.status.busy": "2025-01-17T10:16:06.409871Z",
     "iopub.status.idle": "2025-01-17T10:16:12.82009Z",
     "shell.execute_reply": "2025-01-17T10:16:12.818903Z",
     "shell.execute_reply.started": "2025-01-17T10:16:06.410213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Model(X, X_enc, y, test, test_enc, models)\n",
    "TEST_preds = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"border-radius: 40px; color: white; font-weight: bold; font-size: 150%; text-align: center; background-color:#3cb371; padding: 5px 5px 5px 5px;\">Submission</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alltest = {}\n",
    "for i in os.listdir('./pgs51/submissions/'):\n",
    "    if re.findall('oof.csv', i ) != []:\n",
    "        print(i)\n",
    "        alltest[f'{i}'] = pd.read_csv('./pgs51/submissions/' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.clip(1.11*np.expm1(pd.concat(alltest, axis =1 ).mean(axis = 1)), 0, 6000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('./pgs51/datadown/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = Config.submission\n",
    "submission[Config.target] = np.round(np.clip(1.01*np.expm1(pd.concat(alltest, axis =1 ).mean(axis = 1)), 0, 6000))\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:16:14.2685Z",
     "iopub.status.busy": "2025-01-17T10:16:14.268142Z",
     "iopub.status.idle": "2025-01-17T10:16:14.415851Z",
     "shell.execute_reply": "2025-01-17T10:16:14.414569Z",
     "shell.execute_reply.started": "2025-01-17T10:16:14.268472Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = Config.submission\n",
    "submission[Config.target] = np.round(np.clip(1.01*np.expm1(TEST_preds['Ensemble'].values), 0, 6000))\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-17T10:16:16.919133Z",
     "iopub.status.busy": "2025-01-17T10:16:16.918784Z",
     "iopub.status.idle": "2025-01-17T10:16:17.23657Z",
     "shell.execute_reply": "2025-01-17T10:16:17.235437Z",
     "shell.execute_reply.started": "2025-01-17T10:16:16.919105Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "submission[Config.target].hist(color='#3cb371', bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from andro_auto import AndroLGBMEnsemblePipeline \n",
    "andy = AndroLGBMEnsemblePipeline('./pgs51/models/XGB2_fold2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andy.load_data('./pgs51/dataup/data_X_enc.csv', './pgs51/dataup/data_test_enc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "andy.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    },
    {
     "datasetId": 6413778,
     "sourceId": 10495653,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
